{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzB-7Sx4Cbxw"
      },
      "outputs": [],
      "source": [
        "pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NodzenQCbxz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTs7En7OCbxz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import random\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import SVG\n",
        "from graphviz import Source\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SJ7DdN4Cbx0"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('water_potability.csv')\n",
        "data = data.dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWjdo7j2Cbx0"
      },
      "outputs": [],
      "source": [
        "Y = data['Potability']\n",
        "X = data.drop('Potability',axis=1)\n",
        "X1 = data[['ph','Hardness','Solids','Chloramines','Sulfate']]\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEM_DTZcCbx1"
      },
      "outputs": [],
      "source": [
        "corr_matrix = data.corr()\n",
        "\n",
        "# Visualize the correlation matrix as a heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A27pxb7CCbx1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn import tree\n",
        "\n",
        "# Define the range of max_depth values to test\n",
        "max_depth_range = range(1, 11)\n",
        "\n",
        "# Create an empty list to store the accuracy scores\n",
        "accuracy_scores = []\n",
        "\n",
        "# Train a decision tree classifier for each value of max_depth, and store the accuracy score\n",
        "for depth in max_depth_range:\n",
        "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
        "    clf.fit(X_train, Y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(Y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "max_acc = accuracy_scores[0]\n",
        "best_depth = 1\n",
        "\n",
        "for depth, acc in zip(max_depth_range, accuracy_scores):\n",
        "    if acc > max_acc:\n",
        "        max_acc = acc\n",
        "        best_depth = depth\n",
        "        \n",
        "print(\"Best max_depth:\", best_depth)\n",
        "print(\"Highest accuracy:\", max_acc)\n",
        "\n",
        "\n",
        "# Plot the accuracy scores for each value of max_depth\n",
        "plt.plot(max_depth_range, accuracy_scores)\n",
        "plt.xlabel('max_depth')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj8gL0U_Cbx2"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "treeclf = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
        "treeclf.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_AuVXKACbx3"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "treeclf1 = DecisionTreeClassifier(max_depth=10, random_state=1)\n",
        "treeclf1.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFE9-u8ZCbx3"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "treeclf2 = DecisionTreeClassifier(max_depth=20, random_state=1)\n",
        "treeclf2.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBpE9irrCbx3"
      },
      "outputs": [],
      "source": [
        "Y_pred = treeclf.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, Y_pred)\n",
        "precision = precision_score(Y_test, Y_pred)\n",
        "recall = recall_score(Y_test, Y_pred)\n",
        "f1 = f1_score(Y_test, Y_pred)\n",
        "auc = roc_auc_score(Y_test, Y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC:\", auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feau4jWPCbx4"
      },
      "outputs": [],
      "source": [
        "Y_pred1 = treeclf1.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, Y_pred1)\n",
        "precision = precision_score(Y_test, Y_pred1)\n",
        "recall = recall_score(Y_test, Y_pred1)\n",
        "f1 = f1_score(Y_test, Y_pred1)\n",
        "auc = roc_auc_score(Y_test, Y_pred1)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC:\", auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzPpUSl4Cbx4"
      },
      "outputs": [],
      "source": [
        "Y_pred2 = treeclf2.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, Y_pred2)\n",
        "precision = precision_score(Y_test, Y_pred2)\n",
        "recall = recall_score(Y_test, Y_pred2)\n",
        "f1 = f1_score(Y_test, Y_pred2)\n",
        "auc = roc_auc_score(Y_test, Y_pred2)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"AUC:\", auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "facDamlfCbx4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "cm_dt = confusion_matrix(Y_test, Y_pred)\n",
        "print(\"confusion matrix for DecisionTreeClassifier \\n\",cm_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN-CU7jRCbx5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "cm_dt1 = confusion_matrix(Y_test, Y_pred1)\n",
        "print(\"confusion matrix for DecisionTreeClassifier \\n\",cm_dt1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjXdyBM-Cbx5"
      },
      "outputs": [],
      "source": [
        "feature_cols = X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhFNJfghCbx5"
      },
      "outputs": [],
      "source": [
        "graph = Source(tree.export_graphviz(treeclf, out_file=None,\n",
        "                                    feature_names=feature_cols,\n",
        "                                    class_names=['0', '1', '2', '3', '4'], filled = True))\n",
        "svg = SVG(graph.pipe(format='svg'))\n",
        "display(svg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqub3Gz8Cbx5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    treeclf, X_train, Y_train, cv=5, train_sizes=train_sizes)\n",
        "\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Decision Tree Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpu7EQNQCbx6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    treeclf1, X_train, Y_train, cv=5, train_sizes=train_sizes)\n",
        "\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Decision Tree Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7hbs5mCCbx6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    treeclf2, X_train, Y_train, cv=5, train_sizes=train_sizes)\n",
        "\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Decision Tree Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "2NvKwTr0EDpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
      ],
      "metadata": {
        "id": "uaAyEFRzErW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Now apply the transformations to the data:\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "id": "pAlUNRIoFbnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(5),max_iter=5000)\n",
        "mlp.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "EXuB0e9VF4_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "WTbzxii_GZjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "id": "rHUcKe1tGiDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    mlp, X_train, y_train, cv=5, train_sizes=train_sizes)\n",
        "print(len)\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Neural Net Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TtkIM1nEG0Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters={\n",
        "'hidden_layer_sizes': [(10),(10, 10),(10,20,10), (20), (20,20), (20,50,20), (100),(100,100),(100,500,100)],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=parameters,n_jobs=-1,verbose=2,cv=10)\n",
        "\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "P-8Ssls9JIO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_search.score(X_train, y_train))\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "YTwFn0owLZLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you may need to install networkx with pip\n",
        "import networkx as nx\n",
        "import colorsys\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(3),max_iter=500)\n",
        "mlp.fit(X_train,y_train)\n",
        "predictions = mlp.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "\n",
        "def show_ann(mlp):\n",
        "    hidden_layers_n = len(mlp.coefs_)-1\n",
        "    layers_n = hidden_layers_n + 2\n",
        "    input_neurons_n = len(mlp.coefs_[0])\n",
        "    hidden_neurons_n = [len(mlp.coefs_[i+1]) for i in range(hidden_layers_n)]\n",
        "    output_neurons_n = len(mlp.coefs_[-1][0])\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "    pos = {}\n",
        "\n",
        "    # Create the neurons of the input layer\n",
        "    for i in range(input_neurons_n):\n",
        "        pos['Layer0_{}'.format(i)] = (i,layers_n-1)\n",
        "\n",
        "    for j in range(hidden_layers_n):\n",
        "        # Create the neurons of the j'th hidden layer\n",
        "        prev_layer = j\n",
        "        cur_layer = j+1\n",
        "        if (j == 0):\n",
        "            prev_size = input_neurons_n\n",
        "        else:\n",
        "            prev_size = hidden_neurons_n[j-1]\n",
        "        for i in range(hidden_neurons_n[j]):\n",
        "            pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
        "            for k in range(prev_size):\n",
        "                w = mlp.coefs_[prev_layer][k][i]\n",
        "                G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
        "\n",
        "    # Create the neurons of the output layer\n",
        "    prev_layer = hidden_layers_n\n",
        "    cur_layer = hidden_layers_n+1\n",
        "    for i in range(output_neurons_n):\n",
        "        pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
        "        for k in range(hidden_neurons_n[-1]):\n",
        "            w = mlp.coefs_[prev_layer][k][i]\n",
        "            G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
        "\n",
        "    edges = G.edges()\n",
        "    colors = [colorsys.hsv_to_rgb(0 if G[u][v]['weight'] < 0 else 0.65,\n",
        "                                  1,#min(1, abs(G[u][v]['weight'])),\n",
        "                                  1) for u,v in edges]\n",
        "    weights = [abs(G[u][v]['weight'])*2 for u,v in edges]\n",
        "\n",
        "    nx.draw(G, pos, node_color='y', node_size=100, width=weights, edge_color=colors)\n",
        "    \n",
        "show_ann(grid_search.best_estimator_)"
      ],
      "metadata": {
        "id": "2iuFKq8NGrn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# newm = MLPClassifier(hidden_layer_sizes=(100,500,100))\n",
        "# newm.fit(X_train,y_train)\n",
        "# predictions = newm.predict(X_test)\n",
        "# print(confusion_matrix(y_test,predictions))\n",
        "# show_ann(newm)\n",
        "#Don't run unless you want to wait a while"
      ],
      "metadata": {
        "id": "vk-eutp-dpCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(20,20))\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10))\n",
        "mlp.fit(X_train,y_train)\n",
        "predictions = mlp.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "show_ann(mlp)"
      ],
      "metadata": {
        "id": "mkp0Z5XGd11X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    grid_search.best_estimator_, X_train, y_train, cv=5, train_sizes=train_sizes)\n",
        "print(len)\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Neural Net with 1 Hidden layer of Size 10 Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LIPEOfoxeHQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp = MLPClassifier(hidden_layer_sizes=(20,50,20))\n",
        "# mlp.fit(X_train,y_train)\n",
        "# predictions = mlp.predict(X_test)\n",
        "# print(confusion_matrix(y_test,predictions))\n",
        "# show_ann(mlp)\n",
        "#Will take a while if you run this ^\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    mlp, X_train, y_train, cv=5, train_sizes=train_sizes)\n",
        "print(len)\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Neural Net with 3 Hidden layers of Size 20-50-20 Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IwE8Y_jLrMiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(100,500,100))\n",
        "mlp.fit(X_train,y_train)\n",
        "predictions = mlp.predict(X_test)\n",
        "print(confusion_matrix(y_test,predictions))\n",
        "\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculate the learning curve scores\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    mlp, X_train, y_train, cv=5, train_sizes=train_sizes)\n",
        "print(len)\n",
        "# Calculate the mean and standard deviation of the training scores and testing scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "plt.plot(train_sizes, test_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color=\"g\")\n",
        "plt.xlabel(\"Training Set Size\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Neural Net with 3 Hidden layers of Size 100-500-100 Learning Curve\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gQdwwJN81QU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}